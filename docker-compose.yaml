version: '3.8'

services:
  # 1. Base de données PostgreSQL pour stocker les résultats d'apprentissage
  db:
    image: postgres:13
    container_name: edtech_db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: edtech_db
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init_edtech.sql:/docker-entrypoint-initdb.d/init_edtech.sql
    networks:
      - edtech-network
    restart: always

  # 2. Simulateur EdTech (Votre script Python)
  simulator:
    build: .
    container_name: edtech_simulator
    environment:
      DB_HOST: db
      DB_NAME: edtech_db
      DB_USER: admin
      DB_PASS: password
    depends_on:
      - db
    networks:
      - edtech-network
    restart: on-failure

  # 3. Grafana pour le monitoring des professeurs
  grafana:
    image: grafana/grafana:latest
    container_name: edtech_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - db
    networks:
      - edtech-network
    restart: always

  # 4. Base de données PostgreSQL pour Airflow (métadonnées)
  airflow_db:
    image: postgres:13
    container_name: airflow_db
    environment:
      POSTGRES_DB: airflow_db
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    volumes:
      - airflow_db_data:/var/lib/postgresql/data
    networks:
      - edtech-network
    restart: always

  # 5. Redis pour Airflow (si nécessaire pour certains executors)
  redis:
    image: redis:7-alpine
    container_name: airflow_redis
    networks:
      - edtech-network
    restart: always

  # 6. Airflow Webserver
  airflow-webserver:
    image: apache/airflow:2.8.0
    container_name: airflow-webserver
    depends_on:
      - airflow_db
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow_db/airflow_db
      - AIRFLOW__CORE__FERNET_KEY="5U4u0Csw67u8MQXgqEFvL4jY41KWGe3C9PnXSQk3vo="
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW_UID=1000
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - _PIP_ADDITIONAL_REQUIREMENTS=psycopg2-binary
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - edtech-network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 7. Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.8.0
    container_name: airflow-scheduler
    depends_on:
      - airflow_db
      - db
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow_db/airflow_db
      - AIRFLOW__CORE__FERNET_KEY="5U4u0Csw67u8MQXgqEFvL4jY41KWGe3C9PnXSQk3vo="
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW_UID=1000
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - _PIP_ADDITIONAL_REQUIREMENTS=psycopg2-binary
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - edtech-network
    restart: always

# Définition du réseau pour la communication interne
networks:
  edtech-network:
    driver: bridge

# Persistance des données (pour ne pas perdre vos graphs au redémarrage)
volumes:
  postgres_data:
  airflow_db_data: